# nodes/ome_zarr_flow.py
import os
import asyncio
import numpy as np
import warnings
from registry import register_node

# Dask æ ¸å¿ƒä¾èµ–
try:
    import zarr
    import dask.array as da
    from dask.diagnostics import Callback
    import scipy.ndimage
    import numcodecs

    HAS_LIBS = True
except ImportError:
    HAS_LIBS = False
    print("âš ï¸ ç¼ºå°‘å¿…è¦åº“: pip install dask[complete] zarr scipy")


# ==========================================
#      Dask è¿›åº¦æ¡æ¡¥æ¥å™¨ (æ ¸å¿ƒç»„ä»¶)
# ==========================================

class DaskProgressBridge(Callback):
    """
    ç›‘å¬ Dask ä»»åŠ¡è¿›åº¦ï¼Œå¹¶é€šè¿‡ asyncio æ¡¥æ¥åˆ° ComfyUI å‰ç«¯
    """

    # ğŸ”¥ ä¿®å¤ç‚¹ 1ï¼šå¢åŠ  loop å‚æ•°ï¼Œå…è®¸ä»å¤–éƒ¨ä¼ å…¥ä¸»çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯
    def __init__(self, async_callback, loop=None):
        self.async_callback = async_callback
        # å¦‚æœä¼ å…¥äº† loop å°±ç”¨ä¼ å…¥çš„ï¼Œå¦åˆ™å°è¯•è·å–ï¼ˆåœ¨å­çº¿ç¨‹ä¼šå¤±è´¥ï¼Œæ‰€ä»¥å¿…é¡»ä¼ å…¥ï¼‰
        self.loop = loop or asyncio.get_running_loop()
        self.total_tasks = 0
        self.finished_tasks = 0

    def _start_state(self, dsk, state):
        self.total_tasks = len(state['ready']) + len(state['waiting']) + len(state['running'])
        self._send(0, "ğŸš€ å¼€å§‹è®¡ç®—...")

    def _posttask(self, key, result, dsk, state, worker_id):
        self.finished_tasks += 1
        if self.total_tasks > 0:
            progress = int((self.finished_tasks / self.total_tasks) * 100)
            # åªæœ‰å½“è¿›åº¦å˜åŒ–æ˜æ˜¾æ—¶æ‰å‘é€ï¼Œé¿å… WebSocket æ‹¥å µ
            if self.finished_tasks % 5 == 0 or progress == 100:
                self._send(progress, f"Computing... {progress}%")

    def _finish(self, dsk, state, errored):
        self._send(100, "âœ… å®Œæˆ")

    def _send(self, progress, msg):
        if self.async_callback:
            # ä½¿ç”¨ä¿å­˜çš„ loop çº¿ç¨‹å®‰å…¨åœ°å‘é€æ¶ˆæ¯
            asyncio.run_coroutine_threadsafe(
                self.async_callback(progress, 100, msg), self.loop
            )


# ==========================================
#              ComfyUI èŠ‚ç‚¹å®šä¹‰
# ==========================================

# --- èŠ‚ç‚¹ 1: Reader ---
@register_node("OMEZarrReader")
class OMEZarrReader:
    CATEGORY = "BrainFlow/IO"
    DISPLAY_NAME = "ğŸ“‚ OME-Zarr Reader (Dask)"

    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {"file_path": ("STRING", {"default": "", "multiline": False})}}

    RETURN_TYPES = ("DASK_ARRAY", "DICT")
    RETURN_NAMES = ("dask_arr", "metadata")
    FUNCTION = "load_zarr"

    def load_zarr(self, file_path):
        print(f" [Reader] è¯»å–: {file_path}")
        if not HAS_LIBS or not os.path.exists(file_path):
            return self._get_mock()

        try:
            # 1. æ™ºèƒ½æ¢æµ‹è·¯å¾„
            store = zarr.open(file_path, mode='r')
            array_path = None

            if isinstance(store, zarr.Group):
                print("   > è¯†åˆ«ä¸º Groupï¼Œæ­£åœ¨å¯»æ‰¾ Multiscales å…ƒæ•°æ®...")
                attrs = store.attrs.asdict()
                if 'multiscales' in attrs and len(attrs['multiscales']) > 0:
                    datasets = attrs['multiscales'][0]['datasets']
                    found_path = datasets[0]['path']
                    print(f"   > ğŸ¯ å‘½ä¸­ OME å…ƒæ•°æ®ï¼Œè·¯å¾„: '{found_path}'")
                    array_path = found_path
                else:
                    print("   > âš ï¸ æ—  Multiscalesï¼Œå°è¯•æš´åŠ›æœç´¢æ•°ç»„...")
                    arrays = list(store.array_keys())
                    if arrays:
                        array_path = arrays[0]
                    elif '0' in store:
                        array_path = '0'

            # 2. Dask è¯»å–
            if array_path:
                dask_arr = da.from_zarr(file_path, component=array_path)
            else:
                dask_arr = da.from_zarr(file_path)

            # 3. æ•°æ®ç±»å‹ä¿®å¤ (é˜²æ­¢ Big-Endian æ­»é”)
            if dask_arr.dtype.byteorder == '>':
                print(f"   > âš ï¸ æ£€æµ‹åˆ° Big-Endian ({dask_arr.dtype})ï¼Œæ­£åœ¨è½¬ç ...")
            dask_arr = dask_arr.astype(np.float32)

            print(f"   > âœ… Dask åŠ è½½æˆåŠŸ: Shape={dask_arr.shape}, Chunks={dask_arr.chunksize}")

            metadata = {
                "source_path": os.path.abspath(file_path),
                "shape": dask_arr.shape,
                "dtype": str(dask_arr.dtype)
            }
            return (dask_arr, metadata)

        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise e

    def _get_mock(self):
        arr = da.random.randint(0, 255, size=(10, 512, 512), chunks=(1, 256, 256)).astype(np.float32)
        return (arr, {"source_path": "mock"})


# --- èŠ‚ç‚¹ 2: Filter ---
@register_node("OMEZarrFilter")
class OMEZarrFilter:
    CATEGORY = "BrainFlow/Process"
    DISPLAY_NAME = "âš¡ Image Filter (Dask)"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "dask_arr": ("DASK_ARRAY",),
                "algorithm": (["gaussian", "median", "sobel", "invert"],),
                "sigma": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 20.0}),
            }
        }

    RETURN_TYPES = ("DASK_ARRAY",)
    RETURN_NAMES = ("processed_dask",)
    FUNCTION = "apply_filter"

    def apply_filter(self, dask_arr, algorithm, sigma):
        def process_chunk(chunk, algo=None, s=1.0):
            import scipy.ndimage
            if algo == "gaussian": return scipy.ndimage.gaussian_filter(chunk, sigma=s)
            if algo == "invert": return 255 - chunk
            if algo == "sobel": return scipy.ndimage.sobel(chunk)
            return chunk

        depth = int(sigma * 3) + 1
        res = dask_arr.map_overlap(
            process_chunk, depth=depth, boundary='reflect',
            dtype=dask_arr.dtype, algo=algorithm, s=sigma
        )
        return (res,)


# --- èŠ‚ç‚¹ 3: Writer (ä¿®å¤ Loop ä¼ é€’) ---
# nodes/ome_zarr_flow.py (åªæ›¿æ¢ Writer éƒ¨åˆ†)

# nodes/ome_zarr_flow.py ä¸­çš„ Writer éƒ¨åˆ†

@register_node("OMEZarrWriter")
class OMEZarrWriter:
    CATEGORY = "BrainFlow/IO"
    DISPLAY_NAME = "ğŸ’¾ OME-Zarr Writer (Dask)"
    OUTPUT_NODE = True

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "dask_arr": ("DASK_ARRAY",),
                "metadata": ("DICT",),
                "compression": (["default", "zstd"],),

                # ğŸ”¥ğŸ”¥ğŸ”¥ ã€å…³é”®ä¿®å¤ã€‘æŒªåˆ° required é‡Œï¼Œå¦åˆ™å‰ç«¯çœ‹ä¸è§ï¼
                # è™½ç„¶åœ¨ required é‡Œï¼Œä½†ç»™äº†é»˜è®¤å€¼ ""ï¼Œæ‰€ä»¥é€»è¾‘ä¸Šä¾ç„¶æ˜¯é€‰å¡«çš„
                "output_path": ("STRING", {"default": "", "multiline": False, "placeholder": "ç•™ç©º=è‡ªåŠ¨ä¿å­˜åœ¨ä¸Šä¸€çº§"}),
            },
            # optional æš‚æ—¶ç•™ç©ºï¼Œé˜²æ­¢å‰ç«¯æ¸²æŸ“ä¸å‡º
            "optional": {}
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("saved_path",)
    FUNCTION = "save_zarr"

    async def save_zarr(self, dask_arr, metadata, compression, output_path="", callback=None):
        # 1. æ™ºèƒ½è·¯å¾„è®¡ç®—é€»è¾‘
        # æ³¨æ„ï¼šè¿™é‡Œè¦åšä¸ª strip() åˆ¤æ–­ï¼Œé˜²æ­¢ç”¨æˆ·è¾“å…¥äº†ç©ºæ ¼
        if not output_path or not output_path.strip():
            # è·å–æºæ–‡ä»¶è·¯å¾„
            source = metadata.get("source_path", "")

            if source and "mock://" not in source:
                base_name = os.path.basename(source.rstrip("/\\"))
                name_only = os.path.splitext(base_name)[0]

                # è·å–ä¸Šä¸€çº§ç›®å½•
                current_dir = os.path.dirname(source.rstrip("/\\"))
                parent_dir = os.path.dirname(current_dir)

                # æ‹¼æ¥æ–°è·¯å¾„
                output_path = os.path.join(parent_dir, f"{name_only}_processed.zarr")
                print(f"[Writer] è‡ªåŠ¨å®šä½ä¸Šä¸€çº§ç›®å½•: {output_path}")
            else:
                output_path = "output_processed.zarr"

        abs_path = os.path.abspath(output_path)
        print(f"[Writer] æœ€ç»ˆå†™å…¥è·¯å¾„: {abs_path}")

        main_loop = asyncio.get_running_loop()

        def run_dask():
            # ç¡®ä¿ DaskProgressBridge ç±»å¯ç”¨
            with DaskProgressBridge(callback, loop=main_loop):
                compressor = None
                if compression == "zstd":
                    compressor = numcodecs.Zstd(level=3)

                dask_arr.to_zarr(
                    abs_path,
                    compressor=compressor,
                    overwrite=True
                )

                # å†™å…ƒæ•°æ®
                try:
                    z = zarr.open(abs_path, mode='r+')
                    multiscales = [{
                        "version": "0.4",
                        "name": "processed",
                        "datasets": [{"path": "0"}],
                        "axes": metadata.get("axes", [
                            {"name": "t", "type": "time"},
                            {"name": "c", "type": "channel"},
                            {"name": "z", "type": "space"},
                            {"name": "y", "type": "space"},
                            {"name": "x", "type": "space"}
                        ])
                    }]
                    z.attrs["multiscales"] = multiscales
                except Exception:
                    pass

        await main_loop.run_in_executor(None, run_dask)
        return (abs_path,)