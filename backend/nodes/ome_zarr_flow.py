# nodes/ome_zarr_flow.py
import os
import shutil  # ç”¨äºå¼ºåˆ¶åˆ é™¤æ—§æ–‡ä»¶å¤¹
import asyncio
import numpy as np
import warnings
from registry import register_node

# Dask æ ¸å¿ƒä¾èµ–
try:
    import zarr
    import dask.array as da
    from dask.diagnostics import Callback
    import scipy.ndimage
    import numcodecs

    HAS_LIBS = True
except ImportError:
    HAS_LIBS = False
    print("âš ï¸ ç¼ºå°‘å¿…è¦åº“: pip install dask[complete] zarr scipy")


# ==========================================
#      Dask è¿›åº¦æ¡æ¡¥æ¥å™¨ (é™éŸ³ç‰ˆ)
# ==========================================
class DaskProgressBridge(Callback):
    def __init__(self, async_callback, loop=None):
        self.async_callback = async_callback
        self.loop = loop or asyncio.get_running_loop()
        self.total_tasks = 0
        self.finished_tasks = 0

    def _start_state(self, dsk, state):
        self.total_tasks = len(state['ready']) + len(state['waiting']) + len(state['running'])
        self._send(0, "ğŸš€ å¼€å§‹è®¡ç®—...")

    def _posttask(self, key, result, dsk, state, worker_id):
        self.finished_tasks += 1
        if self.total_tasks > 0:
            progress = int((self.finished_tasks / self.total_tasks) * 100)
            if self.finished_tasks % 5 == 0 or progress == 100:
                self._send(progress, "")

    def _finish(self, dsk, state, errored):
        self._send(100, "âœ… å®Œæˆ")

    def _send(self, progress, msg):
        if self.async_callback:
            asyncio.run_coroutine_threadsafe(
                self.async_callback(progress, 100, msg), self.loop
            )


# ==========================================
#              ComfyUI èŠ‚ç‚¹å®šä¹‰
# ==========================================

@register_node("OMEZarrReader")
class OMEZarrReader:
    CATEGORY = "BrainFlow/IO"
    DISPLAY_NAME = "ğŸ“‚ OME-Zarr Reader (Dask)"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "file_path": ("STRING", {"default": "", "multiline": False}),
                # ä¿ç•™ç”¨æˆ·è¦æ±‚çš„åŠŸèƒ½ï¼šæ§åˆ¶å—å¤§å°å€æ•°
                "chunk_multiple": ("INT", {"default": 1, "min": 1, "max": 16, "step": 1, "label": "Chunk Multiplier"}),
            }
        }

    RETURN_TYPES = ("DASK_ARRAY", "DICT")
    RETURN_NAMES = ("dask_arr", "metadata")
    FUNCTION = "load_zarr"

    def load_zarr(self, file_path, chunk_multiple=1):
        # 1. å¼ºåˆ¶è½¬ç»å¯¹è·¯å¾„
        if not file_path:
            raise ValueError("âŒ æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")

        file_path = os.path.abspath(file_path.strip())

        print(f" [Reader] è¯»å–: {file_path}")
        if not HAS_LIBS or not os.path.exists(file_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")

        try:
            store = zarr.open(file_path, mode='r')
            array_path = None

            # æ™ºèƒ½æ¢æµ‹
            if isinstance(store, zarr.Group):
                attrs = store.attrs.asdict()
                if 'multiscales' in attrs:
                    array_path = attrs['multiscales'][0]['datasets'][0]['path']
                else:
                    arrays = list(store.array_keys())
                    if arrays:
                        array_path = arrays[0]
                    elif '0' in store:
                        array_path = '0'

            if array_path:
                z_arr = store[array_path]
            else:
                z_arr = store

            native_chunks = z_arr.chunks
            print(f"   > ğŸ“Š åŸå§‹ç‰©ç†å—å¤§å°: {native_chunks}")

            if chunk_multiple < 1: chunk_multiple = 1
            new_chunks = tuple(c * chunk_multiple for c in native_chunks)
            print(f"   > ğŸš€ è®¾å®š Dask è°ƒåº¦å—: {new_chunks} (å€æ•°: {chunk_multiple}x)")

            if array_path:
                dask_arr = da.from_zarr(file_path, component=array_path, chunks=new_chunks)
            else:
                dask_arr = da.from_zarr(file_path, chunks=new_chunks)

            dask_arr = dask_arr.astype(np.float32)

            return (dask_arr, {
                "source_path": file_path,  # ä¼ é€’ç»å¯¹è·¯å¾„
                "shape": dask_arr.shape,
                "dtype": str(dask_arr.dtype),
                "chunks": new_chunks
            })

        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥: {e}")
            raise e


@register_node("OMEZarrFilter")
class OMEZarrFilter:
    CATEGORY = "BrainFlow/Process"
    DISPLAY_NAME = "âš¡ Image Filter (Dask)"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "dask_arr": ("DASK_ARRAY",),
                "algorithm": (["gaussian", "median", "sobel", "invert"],),
                "sigma": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 20.0}),
            }
        }

    RETURN_TYPES = ("DASK_ARRAY",)
    RETURN_NAMES = ("processed_dask",)
    FUNCTION = "apply_filter"

    def apply_filter(self, dask_arr, algorithm, sigma):
        def process_chunk(chunk, algo=None, s=1.0):
            import scipy.ndimage
            if algo == "gaussian": return scipy.ndimage.gaussian_filter(chunk, sigma=s)
            if algo == "invert": return 255 - chunk
            if algo == "sobel": return scipy.ndimage.sobel(chunk)
            return chunk

        depth = int(sigma * 3) + 1
        res = dask_arr.map_overlap(
            process_chunk, depth=depth, boundary='reflect',
            dtype=dask_arr.dtype, algo=algorithm, s=sigma
        )
        return (res,)


@register_node("OMEZarrWriter")
class OMEZarrWriter:
    CATEGORY = "BrainFlow/IO"
    DISPLAY_NAME = "ğŸ’¾ OME-Zarr Writer (Dask)"
    OUTPUT_NODE = True

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "dask_arr": ("DASK_ARRAY",),
                "metadata": ("DICT",),
                "compression": (["default", "zstd"],),
            },
            "optional": {
                "output_path": ("STRING", {"default": "", "multiline": False, "placeholder": "é»˜è®¤è‡ªåŠ¨ä¿å­˜"})
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("saved_path",)
    FUNCTION = "save_zarr"

    async def save_zarr(self, dask_arr, metadata, compression, output_path="", callback=None):
        if metadata is None: metadata = {}

        # 1. è‡ªåŠ¨è·¯å¾„é€»è¾‘
        if not output_path or output_path.strip() == "":
            source = metadata.get("source_path", "")

            if source and "mock://" not in source:
                # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ™ºèƒ½è·¯å¾„ä¿®æ­£ã€‘
                # ç›®æ ‡ï¼šæ‰¾åˆ°è¾“å…¥æ–‡ä»¶æ‰€å±çš„â€œæ ¹ç›®å½•â€ï¼Œå¹¶å­˜åˆ°å®ƒçš„æ—è¾¹

                # åœºæ™¯ 1: è¾“å…¥æ˜¯ .../MyImage.zarr/image (OME-Zarr)
                lower_source = source.lower()
                if ".zarr" in lower_source:
                    # æˆªå–åˆ° .zarr ç»“å°¾
                    # ä¾‹å­: E:\Data\File.zarr\image -> E:\Data\File.zarr
                    zarr_end_idx = lower_source.rfind(".zarr") + 5
                    zarr_root = source[:zarr_end_idx]

                    # è·å–çˆ¶çº§: E:\Data
                    parent_dir = os.path.dirname(zarr_root)

                    # è·å–åå­—: File
                    base_name = os.path.basename(zarr_root)
                    name_only = os.path.splitext(base_name)[0]

                # åœºæ™¯ 2: è¾“å…¥æ˜¯æ™®é€šæ–‡ä»¶å¤¹
                else:
                    source_clean = source.rstrip("/\\")
                    parent_dir = os.path.dirname(source_clean)
                    base_name = os.path.basename(source_clean)
                    name_only = os.path.splitext(base_name)[0]

                # ç»“æœ: E:\Data\File_processed.zarr
                output_path = os.path.join(parent_dir, f"{name_only}_processed.zarr")
                print(f"[Writer] è‡ªåŠ¨å®šä½åŸå§‹ç›®å½•: {output_path}")

            else:
                # å…œåº•ï¼šå¦‚æœå®Œå…¨æ²¡æœ‰ source ä¿¡æ¯ï¼Œæ‰ç”¨ä»£ç ç›®å½•
                output_path = "output_processed.zarr"

        abs_path = os.path.abspath(output_path)
        print(f"[Writer] å†™å…¥è·¯å¾„: {abs_path}")

        main_loop = asyncio.get_running_loop()

        def run_dask():
            import numcodecs
            import shutil

            # å†™å…¥å‰å¼ºåˆ¶æ¸…ç† (ä¿ç•™ç”¨æˆ·åŠŸèƒ½)
            if os.path.exists(abs_path):
                try:
                    shutil.rmtree(abs_path)
                except Exception as e:
                    print(f"[Writer] âš ï¸ æ— æ³•æ¸…ç†æ—§æ–‡ä»¶: {e}")

            with DaskProgressBridge(callback, loop=main_loop):
                compressor = None
                if compression == "zstd":
                    compressor = numcodecs.Blosc(cname='zstd', clevel=5, shuffle=numcodecs.Blosc.BITSHUFFLE)
                else:
                    compressor = numcodecs.Blosc(cname='lz4', clevel=5, shuffle=numcodecs.Blosc.SHUFFLE)

                dask_arr.to_zarr(abs_path, compressor=compressor, overwrite=True)

                try:
                    z = zarr.open(abs_path, mode='r+')
                    z.attrs["multiscales"] = [{
                        "version": "0.4", "name": "processed", "datasets": [{"path": "0"}],
                        "axes": metadata.get("axes", [{"name": "t"}, {"name": "c"}, {"name": "z"}, {"name": "y"},
                                                      {"name": "x"}])
                    }]
                except:
                    pass

        await main_loop.run_in_executor(None, run_dask)
        return (abs_path,)